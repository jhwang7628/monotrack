{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assigned-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pipeline.capture_video import CaptureVideo\n",
    "from pipeline.utils import detectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demanding-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/inutard/remote-disk/badminton-vids\"\n",
    "player_name = \"kento\"\n",
    "video_name = \"best-rally-and-highlights-kento-momota-vs-lee-chong-wei-bac-2018-shuttle-amazing-gzvaa5-j-8.mp4\"\n",
    "\n",
    "input_file = \"{}/{}/{}\".format(base_dir, player_name, video_name)\n",
    "output_dir = \"output\"\n",
    "output_file = \"output.mp4\"\n",
    "config_file = \"configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"\n",
    "threshold = 0.8\n",
    "\n",
    "# track_link_len = 100\n",
    "# track_num = 7\n",
    "# track_mag= 30\n",
    "# track_match = 0.2\n",
    "# track_orb_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chemical-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROP:\n",
      "  ENABLED: False\n",
      "  SIZE: [0.9, 0.9]\n",
      "  TYPE: relative_range\n",
      "FORMAT: BGR\n",
      "MASK_FORMAT: polygon\n",
      "MAX_SIZE_TEST: 800\n",
      "MAX_SIZE_TRAIN: 1333\n",
      "MIN_SIZE_TEST: 600\n",
      "MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "RANDOM_FLIP: horizontal\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if needed\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Video input\n",
    "capture_video = CaptureVideo(input_file)\n",
    "\n",
    "cfg = detectron.setup_cfg(config_file=config_file,\n",
    "                          confidence_threshold=threshold,\n",
    "                          cpu=False)\n",
    "\n",
    "print(cfg.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painful-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = Predict(cfg)\n",
    "# #track_pose = TrackPose(link_len=track_link_len, num=track_num, mag=track_mag,\n",
    "# #                       match=track_match, orb_features=track_orb_features)\n",
    "# track_pose = None\n",
    "\n",
    "# separate_background = None\n",
    "# metadata_name = cfg.DATASETS.TEST[0] if len(cfg.DATASETS.TEST) else \"__unused\"\n",
    "# # annotate_video = AnnotateVideo(\"vis_image\", metadata_name,\n",
    "# #                                predictions=track_pose is None,\n",
    "# #                                pose_flows=track_pose is not None)\n",
    "# annotate_video = AnnotateVideo(\"vis_image\", metadata_name,\n",
    "#                                pose_flows=True)\n",
    "\n",
    "# save_video = SaveVideo(\"vis_image\", os.path.join(output_dir, output_file), capture_video.fps)\n",
    "\n",
    "# # Create image processing pipeline\n",
    "# pipeline = (capture_video |\n",
    "#             predict |\n",
    "#             track_pose |\n",
    "#             separate_background |\n",
    "#             annotate_video |\n",
    "#             save_video)\n",
    "\n",
    "# # Iterate through pipeline\n",
    "# num_frames = capture_video.frame_count\n",
    "# num_frames = 300\n",
    "# count = 0\n",
    "# for _ in tqdm(pipeline, total=num_frames):\n",
    "#     count += 1\n",
    "#     if count > num_frames:\n",
    "#         break\n",
    "\n",
    "# # Pipeline cleanup\n",
    "# capture_video.cleanup()\n",
    "# save_video.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "negative-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "model = build_model(cfg)\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "progressive-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2.data.transforms as T\n",
    "import torch\n",
    "aug = T.ResizeShortestEdge(\n",
    "    [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    ")\n",
    "\n",
    "input_format = cfg.INPUT.FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "num_frames = 45 * 30\n",
    "final_images = []\n",
    "centers = [[(0,0), (0,0)]]\n",
    "\n",
    "all_centers = []\n",
    "\n",
    "for _ in tqdm(range(num_frames // batch_size)):\n",
    "    with torch.no_grad():\n",
    "        inputs = []\n",
    "        original = []\n",
    "        for i in range(batch_size):\n",
    "            original_image = capture_video.cap.read()\n",
    "            original.append(original_image)\n",
    "            if input_format == \"RGB\":\n",
    "                # whether the model expects BGR inputs or RGB\n",
    "                original_image = original_image[:, :, ::-1]\n",
    "            height, width = original_image.shape[:2]\n",
    "            image = aug.get_transform(original_image).apply_image(original_image)\n",
    "            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "\n",
    "            input_img = {\"image\": image, \"height\": height, \"width\": width}\n",
    "            inputs.append(input_img)\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        for idx, pred in enumerate(predictions):\n",
    "            image = original[idx]\n",
    "            cen = []\n",
    "            bbox = []\n",
    "            \n",
    "            all_centers.append(pred['instances'].pred_boxes.get_centers())\n",
    "            try:\n",
    "                for player in range(2):\n",
    "                    boxes = pred['instances'][player].pred_boxes\n",
    "                    box = boxes.tensor[0].cpu()\n",
    "                    center = tuple(boxes.get_centers()[0].cpu())\n",
    "                    cen.append(center)\n",
    "                    bbox.append(box)\n",
    "        \n",
    "                norm = lambda a, b: (a[0] - b[0])**2 + (a[1] - b[1])**2\n",
    "                \n",
    "                if len(centers[-1]) == 2 and norm(cen[0], centers[-1][0]) > norm(cen[1], centers[-1][0]):\n",
    "                    cen[0], cen[1] = cen[1], cen[0]\n",
    "                    bbox[0], bbox[1] = bbox[1], bbox[0]\n",
    "                    \n",
    "                for player in range(2):\n",
    "                    color = (255,255,255)#(255 * (player == 0), 255 * (player == 1), 0)\n",
    "\n",
    "                    image = cv2.rectangle(image, tuple(bbox[player][:2]), tuple(bbox[player][2:]), color, 10)\n",
    "                    image = cv2.circle(image, cen[player], 10, color, 10)\n",
    "                    \n",
    "                centers.append(cen)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            final_images.append(image)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    filename='/home/inutard/detectron2-pipeline/' + os.path.join(output_dir, output_file),\n",
    "    fourcc=cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    fps=capture_video.fps,\n",
    "    frameSize=capture_video.frame_size,\n",
    "    isColor=True)\n",
    "\n",
    "for image in final_images:\n",
    "    writer.write(image)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a greedy matching between each adjacent step\n",
    "[len(x) for x in all_centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-saturn",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
