{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from ai_badminton.trajectory import Trajectory\n",
    "from ai_badminton.hit_detector import AdhocHitDetector, MLHitDetector\n",
    "from ai_badminton.pose import Pose, read_player_poses, process_pose_file\n",
    "from ai_badminton.court import Court, read_court\n",
    "from ai_badminton.video_annotator import annotate_video\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from scipy.stats import mode\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "data_dir = '/home/work_space/data'\n",
    "\n",
    "def read_court(filename):\n",
    "    file = open(filename, 'r')\n",
    "    coordinates = [[float(x) for x in line.split(';')] for line in file]\n",
    "    return coordinates\n",
    "\n",
    "def visualize(x, y):\n",
    "    print(x.shape, y.shape)\n",
    "    cdict = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "    plt.figure()\n",
    "    for g in np.unique(y):\n",
    "        ix = np.where(y == g)\n",
    "        plt.scatter(*x[ix, -4:, :].T, c=cdict[g], label=g)\n",
    "        plt.scatter(*x[ix, 0, :].T, c=cdict[g], label=g)\n",
    "    plt.show()\n",
    "    \n",
    "def resample(series, s):\n",
    "    flatten = False\n",
    "    if len(series.shape) == 1:\n",
    "        series.resize((series.shape[0], 1))\n",
    "        series = series.astype('float64')\n",
    "        flatten = True\n",
    "    series = resize(\n",
    "        series, (int(s * series.shape[0]), series.shape[1]),\n",
    "    )\n",
    "    if flatten:\n",
    "        series = series.flatten()\n",
    "    return series   \n",
    "\n",
    "eps = 1e-6\n",
    "def reflect(x):\n",
    "    x = np.array(x)\n",
    "    idx = np.abs(x) < eps\n",
    "    for i in range(0, x.shape[1], 2):\n",
    "        x[:, i] = -x[:, i]\n",
    "    x[idx] = 0.\n",
    "    return x\n",
    "\n",
    "# Identify first hit by distance to pose\n",
    "# and then alternate hits\n",
    "def dist_to_pose(pose, p):\n",
    "    pose = pose.reshape(17, 2)\n",
    "    p = p.reshape(1, 2)\n",
    "    D = np.sum((pose - p) * (pose - p), axis=1)\n",
    "    return min(D)\n",
    "\n",
    "def scale_data(x):\n",
    "    x = np.array(x)\n",
    "    def scale_by_col(x, cols):\n",
    "        x_ = np.array(x[:, cols])\n",
    "        idx = np.abs(x_) < eps\n",
    "        m, M = np.min(x_[~idx]), np.max(x_[~idx])\n",
    "        x_[~idx] = (x_[~idx] - m) / (M - m) + 1\n",
    "        x[:, cols] = x_\n",
    "        return x\n",
    "\n",
    "    even_cols = [2*i for i in range(x.shape[1] // 2)]\n",
    "    odd_cols = [2*i+1 for i in range(x.shape[1] // 2)]\n",
    "    x = scale_by_col(x, even_cols)\n",
    "    x = scale_by_col(x, odd_cols)\n",
    "    return x\n",
    "\n",
    "identity = lambda x: x\n",
    "def drop_consecutive(x, rep_value=0.):\n",
    "    x = np.array(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        j = random.randint(0, num_consec-1)\n",
    "        x[i][max(0, 78*(j-2)):min(78*(j+2), 78*num_consec)] = rep_value\n",
    "    return x\n",
    "\n",
    "def corrupt_consecutive(x, rep_value=0.):\n",
    "    x = np.array(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        j = random.randint(0, num_consec-1)\n",
    "        l, r = max(0, 78*(j-2)), min(78*(j+2), 78*num_consec)\n",
    "        x[i][l:r] = np.random.rand(1, r-l)\n",
    "    return x\n",
    "\n",
    "def drop_data(x, rep_value=0, keep_prob=0.95):\n",
    "    x = np.array(x)\n",
    "    # Corrupt 15% of the data\n",
    "    indices = np.random.choice(\n",
    "        np.arange(x.size), replace=False,\n",
    "        size=int(x.size * (1 - keep_prob))\n",
    "    )\n",
    "    x[np.unravel_index(indices, x.shape)] = rep_value\n",
    "    return x\n",
    "\n",
    "def corrupt_data(x, keep_prob=0.95):\n",
    "    x = np.array(x)\n",
    "    idx = np.abs(x) < eps\n",
    "    # Corrupt 15% of the data\n",
    "    indices = np.random.choice(\n",
    "        np.arange(x.size), replace=False,\n",
    "        size=int(x.size * (1 - keep_prob))\n",
    "    )\n",
    "    shape = x[np.unravel_index(indices, x.shape)].shape\n",
    "    low, hi = max(np.min(x[:,0::2]), np.min(x[:,1::2])), min(np.max(x[:,0::2]), np.max(x[:,1::2]))\n",
    "    target = np.random.rand(*shape) * (hi-low) + low\n",
    "    x[np.unravel_index(indices, x.shape)] = target\n",
    "    x[idx] = 0.\n",
    "    return x\n",
    "\n",
    "def jiggle_and_rotate(x):\n",
    "    # Randomly shift by a vector in [0, 30]\n",
    "    # and rotate by a random amount between -10 and 10 degrees\n",
    "    x = np.array(x.reshape((x.shape[0], x.shape[1] // 2, 2)))\n",
    "    idx = np.abs(x) < eps\n",
    "    # shift does nothing when we rescale after\n",
    "    # shift = np.random.rand(1, 2) * 30\n",
    "    angle = (np.random.rand() - 0.5) * math.pi / 180 * 30\n",
    "    rotate = np.array([[math.cos(angle), -math.sin(angle)], \n",
    "                       [math.sin(angle), math.cos(angle)]])\n",
    "    a, b = np.random.rand() * 0.1, np.random.rand() * 0.1\n",
    "    shear = np.array([[1+a*b, a], \n",
    "                      [b,     1]])\n",
    "    x = x @ shear @ rotate\n",
    "    x[idx] = 0.\n",
    "    x = x.reshape((x.shape[0], x.shape[1] * 2))\n",
    "    return x\n",
    "\n",
    "drop_random_and_jiggle = lambda x: drop_data(jiggle_and_rotate(x), 0, 0.95)\n",
    "corrupt_random_and_jiggle = lambda x: corrupt_data(jiggle_and_rotate(x), 0.95)\n",
    "drop_consecutive_and_jiggle = lambda x: drop_consecutive(jiggle_and_rotate(x))\n",
    "corrupt_consecutive_and_jiggle = lambda x: corrupt_consecutive(jiggle_and_rotate(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match1 1_02_03 is hard [1, 0] [5266.931744878903, 1e+99]\n",
      "Manual label applied.\n",
      "match1 1_02_04 1 [2, 0]\n",
      "Manual label applied.\n",
      "match1 1_01_00 2 [3, 7]\n",
      "match1 1_06_06 is hard [2, 3] [682559.7210577, 974.929612210002]\n",
      "match1 1_02_02 1 [4, 2]\n",
      "Manual label applied.\n",
      "match1 1_06_08 1 [4, 0]\n",
      "Manual label applied.\n",
      "match1 1_03_06 2 [3, 5]\n",
      "match1 1_06_09 1 [11, 3]\n",
      "match1 1_02_01 2 [0, 6]\n",
      "Manual label applied.\n",
      "match1 1_02_00 1 [11, 7]\n",
      "match1 1_03_04 2 [0, 3]\n",
      "Manual label applied.\n",
      "match1 1_03_05 2 [3, 10]\n",
      "match2 1_02_03 2 [1, 4]\n",
      "match2 1_08_12 1 [6, 0]\n",
      "match2 1_08_11 is hard [4, 3] [1116.9742584088992, 1204.2098843728977]\n",
      "match2 1_04_03 2 [2, 4]\n",
      "match2 1_06_08 is hard [4, 3] [2477.160291976099, 68.54406989089972]\n",
      "match2 1_09_12 1 [8, 3]\n",
      "match2 1_00_02 1 [12, 6]\n",
      "match2 1_06_09 2 [1, 9]\n",
      "match3 1_01_00 2 [0, 13]\n",
      "match3 2_10_12 1 [5, 1]\n",
      "match3 1_12_17 is hard [4, 4] [5.7387200101000175, 354.46816523080025]\n",
      "match3 1_08_10 is hard [1, 2] [4412.541963218499, 1204.3166403475989]\n",
      "Manual label applied.\n",
      "match3 2_18_15 2 [1, 36]\n",
      "match3 2_04_07 2 [6, 15]\n",
      "match3 3_11_10 2 [1, 5]\n",
      "match4 3_18_17 1 [14, 10]\n",
      "match4 2_05_07 2 [6, 8]\n",
      "match4 2_14_17 is hard [4, 4] [1767.4863214409038, 330555.28941241157]\n",
      "match4 1_15_10 1 [10, 6]\n",
      "match4 1_03_02 1 [11, 5]\n",
      "match4 3_07_05 is hard [2, 3] [1027.9010970708982, 376614.00944341]\n",
      "match4 2_02_05 2 [6, 12]\n",
      "match4 3_02_00 2 [3, 10]\n",
      "match5 2_15_13 1 [20, 2]\n",
      "match5 1_01_02 1 [16, 3]\n",
      "match5 2_20_17 1 [26, 2]\n",
      "match5 1_21_19 2 [1, 28]\n",
      "match5 1_01_01 2 [2, 26]\n",
      "match5 1_19_18 2 [0, 9]\n",
      "match6 1_19_12 2 [1, 9]\n",
      "match6 1_15_06 2 [2, 24]\n",
      "match6 1_11_04 1 [13, 7]\n",
      "match6 1_05_03 2 [6, 32]\n",
      "match6 1_02_00 1 [9, 5]\n",
      "match7 2_05_03 2 [6, 24]\n",
      "match7 2_14_15 1 [11, 7]\n",
      "match7 3_08_05 2 [0, 17]\n",
      "match7 1_02_01 1 [20, 3]\n",
      "match7 1_12_13 1 [15, 5]\n",
      "match8 3_15_08 1 [4, 0]\n",
      "match8 2_03_06 2 [3, 31]\n",
      "match8 1_01_00 1 [10, 1]\n",
      "match8 2_10_12 1 [15, 2]\n",
      "match8 3_17_12 2 [4, 13]\n",
      "match8 3_21_13 1 [11, 1]\n",
      "match8 1_05_13 2 [2, 7]\n",
      "match8 3_02_00 is hard [1, 1] [580117.6390523058, 128.41058857959956]\n",
      "Manual label applied.\n",
      "match9 1_02_03 2 [0, 13]\n",
      "match9 1_01_03 2 [6, 30]\n",
      "match9 1_07_10 1 [17, 4]\n",
      "match9 1_05_06 1 [11, 0]\n",
      "match9 1_07_11 2 [1, 9]\n",
      "match9 1_07_14 1 [5, 3]\n",
      "match9 1_06_06 1 [7, 1]\n",
      "match9 1_07_07 1 [8, 3]\n",
      "match9 1_04_05 1 [9, 1]\n",
      "match10 2_04_02 1 [7, 4]\n",
      "match10 1_03_01 is hard [9, 8] [990.7883616545008, 3734.0805698024]\n",
      "match10 2_14_08 2 [3, 20]\n",
      "match10 1_03_03 2 [6, 12]\n",
      "match10 1_12_16 1 [10, 4]\n",
      "match11 1_07_06 1 [11, 1]\n",
      "match11 2_15_04 1 [18, 6]\n",
      "match11 2_05_00 1 [10, 3]\n",
      "match11 1_03_01 2 [2, 11]\n",
      "match11 1_13_13 1 [23, 7]\n",
      "match12 3_03_03 2 [2, 11]\n",
      "match12 2_01_01 2 [0, 14]\n",
      "match12 1_01_00 1 [20, 1]\n",
      "match12 2_05_14 1 [23, 2]\n",
      "match12 1_10_12 2 [11, 14]\n",
      "match13 2_07_05 1 [5, 0]\n",
      "match13 2_17_11 2 [2, 13]\n",
      "match13 1_17_15 2 [4, 7]\n",
      "match13 1_09_10 1 [14, 6]\n",
      "match13 2_06_05 1 [24, 6]\n",
      "match13 2_09_08 2 [1, 3]\n",
      "match14 2_21_17 2 [3, 11]\n",
      "match14 2_13_06 2 [4, 13]\n",
      "match14 1_17_14 2 [5, 20]\n",
      "match14 2_15_10 1 [4, 1]\n",
      "match14 2_19_13 1 [19, 3]\n",
      "match15 1_21_12 is hard [4, 4] [1636.9464822099958, 285105.35345104]\n",
      "match15 2_14_08 1 [6, 0]\n",
      "match15 2_18_14 2 [8, 27]\n",
      "match15 2_16_12 2 [6, 15]\n",
      "match15 2_19_14 2 [3, 22]\n",
      "match16 3_12_06 1 [12, 8]\n",
      "match16 2_08_08 1 [14, 3]\n",
      "match16 3_14_09 1 [10, 1]\n",
      "match16 3_17_16 1 [8, 5]\n",
      "match16 1_03_06 2 [3, 16]\n",
      "match16 1_13_20 1 [12, 0]\n",
      "match17 1_15_13 1 [12, 2]\n",
      "match17 2_01_01 1 [9, 6]\n",
      "match17 2_08_05 2 [2, 14]\n",
      "match17 1_02_02 2 [2, 8]\n",
      "match17 2_15_11 1 [12, 1]\n",
      "match17 2_18_11 2 [5, 8]\n",
      "match18 2_02_02 1 [15, 1]\n",
      "match18 3_03_05 2 [1, 27]\n",
      "match18 3_16_17 1 [12, 1]\n",
      "match18 3_20_19 1 [12, 4]\n",
      "match18 3_12_14 2 [2, 12]\n",
      "match18 1_06_12 1 [10, 3]\n",
      "match19 1_01_03 1 [21, 6]\n",
      "match19 2_14_08 2 [2, 8]\n",
      "match19 1_07_08 2 [1, 11]\n",
      "match19 1_01_01 2 [2, 11]\n",
      "match19 2_12_06 1 [12, 2]\n",
      "match20 2_07_08 1 [9, 3]\n",
      "match20 2_00_01 1 [9, 0]\n",
      "match20 1_11_10 2 [6, 9]\n",
      "match20 1_09_05 2 [5, 15]\n",
      "match20 2_05_08 1 [22, 3]\n",
      "match20 2_19_14 2 [3, 13]\n",
      "match21 1_16_17 1 [21, 2]\n",
      "match21 2_12_08 2 [2, 11]\n",
      "match21 1_19_19 1 [7, 2]\n",
      "match21 2_04_04 1 [10, 4]\n",
      "match21 1_02_01 2 [2, 14]\n",
      "match21 2_02_03 2 [1, 16]\n",
      "match21 2_09_08 1 [19, 5]\n",
      "match22 2_17_18 1 [16, 7]\n",
      "match22 2_18_18 2 [2, 17]\n",
      "match22 1_07_02 1 [10, 3]\n",
      "match22 3_15_13 1 [10, 4]\n",
      "match22 1_02_01 1 [26, 6]\n"
     ]
    }
   ],
   "source": [
    "num_consec = 12 # Jui: read the paper for the correct parameters\n",
    "left_window = 6\n",
    "right_window = 0\n",
    "matches = list('match' + str(i) for i in range(1, 23))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, minmax_scale\n",
    "\n",
    "manual_label = {\n",
    "    ('match1', '1_02_04'): 2,\n",
    "    ('match1', '1_06_08'): 1,\n",
    "    ('match1', '1_02_02'): 1,\n",
    "    ('match1', '1_02_01'): 2,\n",
    "    ('match1', '1_03_04'): 2,\n",
    "    ('match1', '1_02_03'): 1,\n",
    "    ('match3', '1_08_10'): 2,\n",
    "    ('match8', '3_02_00'): 2,\n",
    "}\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for match in matches:\n",
    "    basedir = f'{data_dir}/%s' % match\n",
    "    for video in os.listdir('%s/rally_video/' % basedir):\n",
    "        if '.mp4' not in video:\n",
    "            continue\n",
    "        for speed in [1.0]:#[0.833, 0.9, 1.0, 1.1, 1.2]:\n",
    "            rally, _ = os.path.splitext(video)\n",
    "            trajectory = Trajectory(\n",
    "                '%s/ball_trajectory/%s_ball_predicted.csv' % (basedir, rally),\n",
    "                interp=False\n",
    "            )\n",
    "            hit = pd.read_csv('%s/shot/%s_hit.csv' % (basedir, rally))\n",
    "\n",
    "            poses = read_player_poses('%s/poses/%s' % (basedir, rally))\n",
    "            bottom_player, top_player = poses[0], poses[1]\n",
    "\n",
    "            x_list, y_list = [], []\n",
    "            court_pts = read_court('%s/court/%s.out' % (basedir, rally))\n",
    "            corners = np.array([court_pts[1], court_pts[2], court_pts[0], court_pts[3]]).flatten()\n",
    "            \n",
    "            cap = cv2.VideoCapture('%s/rally_video/%s' % (basedir, video))\n",
    "            _, frame = cap.read()\n",
    "            height, width = frame.shape[:2]         \n",
    "            \n",
    "            hit = hit.values[:, 1]\n",
    "            if speed < 1:\n",
    "                # NTS: speed < 1 actually means sequence gets faster\n",
    "                hit = hit + shift(hit, -1) + shift(hit, +1)\n",
    "                        \n",
    "            trajectory.X = resample(np.array(trajectory.X), speed)\n",
    "            trajectory.Y = resample(np.array(trajectory.Y), speed)\n",
    "            hit = resample(hit, speed).round()\n",
    "            bottom_player = resample(bottom_player.values, speed)\n",
    "            top_player = resample(top_player.values, speed)\n",
    "            \n",
    "            y_new = np.array(hit)\n",
    "            if speed != 1:\n",
    "                for i in range(y_new.shape[0] - 1):\n",
    "                    if i+3 < y_new.shape[0] and y_new[i] and y_new[i+1] and y_new[i+2] and y_new[i+3]:\n",
    "                        y_new[i] = y_new[i+1] = y_new[i+3] = 0.\n",
    "                    if i+2 < y_new.shape[0] and y_new[i] and y_new[i+1] and y_new[i+2]:\n",
    "                        y_new[i] = y_new[i+2] = 0.\n",
    "                    if y_new[i] and y_new[i+1]:\n",
    "                        y_new[i] = 0.\n",
    "                        \n",
    "            # Majority vote for who started the rally\n",
    "            # If hit number is odd, then whoever started the rally\n",
    "            # is the opposite of whoever was detected.\n",
    "            votes = [0, 0]\n",
    "            best_dist = [1e99, 1e99]\n",
    "            nhit = 0\n",
    "            for i in range(y_new.shape[0]):\n",
    "                if not y_new[i]:\n",
    "                    continue\n",
    "\n",
    "                p = np.array([trajectory.X[i], trajectory.Y[i]])\n",
    "                db = dist_to_pose(bottom_player[i], p)\n",
    "                dt = dist_to_pose(top_player[i], p)\n",
    "                person = 0\n",
    "                if db < dt:\n",
    "                    person = 1\n",
    "                else:\n",
    "                    person = 2\n",
    "\n",
    "                if nhit % 2:\n",
    "                    person = 3 - person\n",
    "\n",
    "                votes[person - 1] += 1\n",
    "                best_dist[person - 1] = min(best_dist[person - 1], min(db, dt))\n",
    "\n",
    "                nhit += 1\n",
    "\n",
    "            if abs(votes[0] - votes[1]) < 2:\n",
    "                print(match, rally, 'is hard', votes, best_dist)\n",
    "            else:\n",
    "                print(match, rally, 1 if votes[0] > votes[1] else 2, votes)\n",
    "\n",
    "            last = 2 if votes[0] > votes[1] else 1\n",
    "            if (match, rally) in manual_label:\n",
    "                last = 3 - manual_label[match, rally]\n",
    "                print('Manual label applied.')\n",
    "            for i in range(y_new.shape[0]):\n",
    "                if not y_new[i]:\n",
    "                    continue\n",
    "\n",
    "                y_new[i] = 3 - last\n",
    "                last = y_new[i]\n",
    "                \n",
    "            for i in range(num_consec):\n",
    "                end = min(len(trajectory.X), len(hit))-num_consec+i+1\n",
    "                x_bird = np.array(list(zip(trajectory.X[i:end], trajectory.Y[i:end])))\n",
    "\n",
    "                # Use entire pose\n",
    "                x_pose = np.hstack([bottom_player[i:end], top_player[i:end]])\n",
    "                x = np.hstack([x_bird, x_pose, np.array([corners for j in range(i, end)])])\n",
    "                y = y_new[i:end]\n",
    "                x_list.append(x)\n",
    "                y_list.append(y)\n",
    "\n",
    "            x_t = np.hstack(x_list)\n",
    "            if right_window > 0:\n",
    "                y_t = np.max(np.column_stack(y_list[left_window:-right_window]), axis=1)\n",
    "            else:\n",
    "                y_t = np.max(np.column_stack(y_list[left_window:]), axis=1)\n",
    "                    \n",
    "            # y_t = np.column_stack(y_list).astype('float')\n",
    "            # y_t = mode(np.column_stack(y_list[left_window:-right_window]), axis=1).mode.flatten()\n",
    "            # for i in range(y_t.shape[0]):\n",
    "            #     val, cnt = np.unique(y_t[i], return_counts=True)\n",
    "            #     val = val.astype('int')\n",
    "            #     cnt = cnt.astype('float')\n",
    "            #     y_t[i, 0:3] = 0\n",
    "            #     y_t[i, val] = cnt / subwindow_size\n",
    "            # y_t = y_t[:, :3]\n",
    "\n",
    "            augmentations = [identity]# + [jiggle_and_rotate]*2# + [drop_consecutive_and_jiggle] + [corrupt_consecutive_and_jiggle]\n",
    "            #+ [corrupt_and_jiggle] + [drop_and_jiggle]# + [jiggle_and_rotate] + [drop_and_jiggle] + [corrupt_and_jiggle]\n",
    "            for transform in augmentations:\n",
    "                x_train.append(scale_data(transform(x_t)))\n",
    "                y_train.append(y_t)\n",
    "                \n",
    "                # x_train.append(scale_data(transform(reflect(x_t))))\n",
    "                # y_train.append(y_t)\n",
    "\n",
    "x_train = np.vstack(x_train)\n",
    "y_train = np.hstack(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_09_07.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_09_07.mp4 1 [20, 3]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_07_06.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_07_06.mp4 is hard [5, 6] [1689.2631038501008, 1808.8286952228966]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_06_03.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_06_03.mp4 2 [4, 8]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_05_02.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_05_02.mp4 1 [13, 3]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/2_03_10.mp4\n",
      "/home/work_space/data/test_match1/rally_video/2_03_10.mp4 1 [18, 1]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_07_03.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_07_03.mp4 1 [19, 4]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/2_03_08.mp4\n",
      "/home/work_space/data/test_match1/rally_video/2_03_08.mp4 is hard [2, 1] [268547.24660605, 319816.2775039634]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/2_02_07.mp4\n",
      "/home/work_space/data/test_match1/rally_video/2_02_07.mp4 1 [6, 0]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_05_03.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_05_03.mp4 1 [11, 1]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_07_04.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_07_04.mp4 is hard [2, 1] [369156.92521387694, 371513.396241242]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_09_06.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_09_06.mp4 is hard [1, 1] [291310.29732485, 321908.5355976704]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_04_04.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_04_04.mp4 is hard [4, 3] [1124.9216913124026, 92896.5303993429]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_19_15.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_19_15.mp4 2 [5, 18]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_03_03.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_03_03.mp4 2 [5, 7]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/2_08_12.mp4\n",
      "/home/work_space/data/test_match2/rally_video/2_08_12.mp4 1 [18, 3]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_11_11.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_11_11.mp4 2 [5, 18]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_13_12.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_13_12.mp4 2 [4, 15]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/2_02_05.mp4\n",
      "/home/work_space/data/test_match2/rally_video/2_02_05.mp4 2 [7, 19]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_10_16.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_10_16.mp4 2 [2, 9]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_08_08.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_08_08.mp4 2 [1, 8]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_05_02.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_05_02.mp4 2 [1, 25]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_06_06.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_06_06.mp4 2 [2, 6]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_03_02.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_03_02.mp4 1 [9, 3]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_09_12.mp4\n",
      "Failed data fetch for video: /home/work_space/data/test_match3/rally_video/1_09_12.mp4\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_06_05.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_06_05.mp4 2 [2, 5]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_05_03.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_05_03.mp4 2 [0, 3]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_02_00.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_02_00.mp4 2 [2, 20]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_08_09.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_08_09.mp4 2 [0, 6]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_09_15.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_09_15.mp4 1 [5, 1]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# Get validation data\n",
    "x_val, y_val = [], []\n",
    "base_dir = Path(data_dir)\n",
    "for match_dir in base_dir.iterdir():\n",
    "    if 'test_match' not in str(match_dir):\n",
    "        continue\n",
    "    rally_video_path = match_dir / \"rally_video\"\n",
    "\n",
    "    for video_path in rally_video_path.iterdir():\n",
    "        try:\n",
    "            print(f\"Fetching video: {str(video_path)}\")\n",
    "            stem = video_path.stem\n",
    "            trajectory_path = match_dir / \"ball_trajectory\" / (stem + \"_ball_predicted.csv\")\n",
    "            hit_path = match_dir / \"shot\" / (stem + \"_hit.csv\")\n",
    "            court_path = match_dir / \"court\" / (stem + \".out\")\n",
    "            poses_path_prefix = match_dir / \"poses\" / stem\n",
    "\n",
    "            poses_bottom_path = Path(str(poses_path_prefix) + \"_player_bottom.csv\") \n",
    "            poses_top_path = Path(str(poses_path_prefix) + \"_player_top.csv\") \n",
    "\n",
    "            assert trajectory_path.is_file(), f\"Trajectory file does not exist for: {video_path}\"\n",
    "            assert hit_path.is_file(), f\"Hit file does not exist for: {video_path}\"\n",
    "            assert court_path.is_file(), f\"Court file does not exist for: {video_path}\"\n",
    "            assert poses_bottom_path.is_file(), f\"Bottom pose file does not exist for: {video_path}\"\n",
    "            assert poses_top_path.is_file(), f\"Top pose file does not exist for: {video_path}\"\n",
    "\n",
    "            trajectory = Trajectory(str(trajectory_path), interp=False)\n",
    "            hit = pd.read_csv(str(hit_path))\n",
    "            poses = read_player_poses(str(poses_path_prefix))\n",
    "            bottom_player, top_player = poses[0], poses[1]\n",
    "            court_pts = read_court(str(court_path))\n",
    "            corners = np.array([court_pts[1], court_pts[2], court_pts[0], court_pts[3]]).flatten()\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            _, frame = cap.read()\n",
    "            height, width = frame.shape[:2]\n",
    "        except:\n",
    "            print('Failed data fetch for video:', str(video_path))\n",
    "            continue\n",
    "        \n",
    "        # Identify first hit by distance to pose\n",
    "        # and then alternate hits\n",
    "        def dist_to_pose(pose, p):\n",
    "            pose = pose.reshape(17, 2)\n",
    "            p = p.reshape(1, 2)\n",
    "            D = np.sum((pose - p) * (pose - p), axis=1)\n",
    "            return min(D)\n",
    "\n",
    "        y_new = np.array(hit.hit.to_numpy())\n",
    "        # Majority vote for who started the rally\n",
    "        # If hit number is odd, then whoever started the rally\n",
    "        # is the opposite of whoever was detected.\n",
    "        votes = [0, 0]\n",
    "        best_dist = [1e99, 1e99]\n",
    "        nhit = 0\n",
    "        for i in range(y_new.shape[0]):\n",
    "            if not y_new[i]:\n",
    "                continue\n",
    "\n",
    "            p = np.array([trajectory.X[i], trajectory.Y[i]])\n",
    "            db = dist_to_pose(bottom_player.values[i], p)\n",
    "            dt = dist_to_pose(top_player.values[i], p)\n",
    "            person = 0\n",
    "            if db < dt:\n",
    "                person = 1\n",
    "            else:\n",
    "                person = 2\n",
    "\n",
    "            if nhit % 2:\n",
    "                person = 3 - person\n",
    "\n",
    "            votes[person - 1] += 1\n",
    "            best_dist[person - 1] = min(best_dist[person - 1], min(db, dt))\n",
    "\n",
    "            nhit += 1\n",
    "\n",
    "        if abs(votes[0] - votes[1]) < 2:\n",
    "            print(rally_video_path / video_path, 'is hard', votes, best_dist)\n",
    "        else:\n",
    "            print(rally_video_path / video_path, 1 if votes[0] > votes[1] else 2, votes)\n",
    "\n",
    "        last = 2 if votes[0] > votes[1] else 1\n",
    "        if votes[0] == votes[1]:\n",
    "            last = 1 if best_dist[0] < best_dist[1] else 2\n",
    "\n",
    "        for i in range(y_new.shape[0]):\n",
    "            if not y_new[i]:\n",
    "                continue\n",
    "\n",
    "            y_new[i] = 3 - last\n",
    "            last = y_new[i]\n",
    "\n",
    "        # last = 0\n",
    "        # last_id = -1\n",
    "        # for i in range(y_new.shape[0]):\n",
    "        #     if y_new[i] > 0:\n",
    "        #         if last_id >= 0:\n",
    "        #             for j in range(last_id, i):\n",
    "        #                 y_new[j] = last\n",
    "        #         last = y_new[i]\n",
    "        #         last_id = i\n",
    "        #     y_new[i] = last\n",
    "\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for i in range(num_consec):\n",
    "            end = min(len(trajectory.X), len(hit.hit))-num_consec+i+1\n",
    "            x_bird = np.array(list(zip(trajectory.X[i:end], trajectory.Y[i:end])))\n",
    "\n",
    "            # Use entire pose\n",
    "            x_pose = np.hstack([bottom_player.values[i:end], top_player.values[i:end]])\n",
    "            x = np.hstack([x_bird, x_pose, np.array([corners for j in range(i, end)])])\n",
    "\n",
    "            y = y_new[i:end]\n",
    "            x_list.append(x)\n",
    "            y_list.append(y)\n",
    "            \n",
    "        x_t = np.hstack(x_list)\n",
    "        if right_window > 0:\n",
    "            y_t = np.max(np.column_stack(y_list[left_window:-right_window]), axis=1)\n",
    "        else:\n",
    "            y_t = np.max(np.column_stack(y_list[left_window:]), axis=1)\n",
    "\n",
    "            \n",
    "        # y_t = np.column_stack(y_list).astype('float')\n",
    "        # y_t = mode(np.column_stack(y_list[left_window:-right_window]), axis=1).mode.flatten()\n",
    "        # for i in range(y_t.shape[0]):\n",
    "        #     val, cnt = np.unique(y_t[i], return_counts=True)\n",
    "        #     val = val.astype('int')\n",
    "        #     cnt = cnt.astype('float')\n",
    "        #     y_t[i, 0:3] = 0\n",
    "        #     y_t[i, val] = cnt / subwindow_size\n",
    "        # y_t = y_t[:, :3]\n",
    "\n",
    "        x_val.append(scale_data(x_t))\n",
    "        y_val.append(y_t)\n",
    "\n",
    "x_val = np.vstack(x_val)\n",
    "y_val = np.hstack(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hitnet training with automatic hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subsample the training and validation to have 50/50 hit events and non-hit events\n",
    "# (otherwise we can get high accuracy trivially from the nonhit events)\n",
    "import random\n",
    "\n",
    "p = sum(y_train > 0) / sum(y_train == 0)\n",
    "subsample = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    if random.random() < p or y_train[i]:\n",
    "        subsample.append(i)\n",
    "        \n",
    "x_train = x_train[subsample]\n",
    "y_train = y_train[subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = sum(y_val > 0) / sum(y_val == 0)\n",
    "subsample = []\n",
    "for i in range(x_val.shape[0]):\n",
    "    if random.random() < p or y_val[i]:\n",
    "        subsample.append(i)\n",
    "        \n",
    "x_val = x_val[subsample]\n",
    "y_val = y_val[subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "# Use tensorflow's dataset function to do augmentation on the fly\n",
    "choices = [identity, \n",
    "           drop_consecutive, \n",
    "           drop_data, \n",
    "           corrupt_consecutive, \n",
    "           corrupt_data, \n",
    "           jiggle_and_rotate, \n",
    "           drop_random_and_jiggle, \n",
    "           corrupt_random_and_jiggle, \n",
    "           drop_consecutive_and_jiggle,\n",
    "           corrupt_consecutive_and_jiggle]\n",
    "probs = [2, 1, 1, 1, 1, 5, 1, 1, 9, 9]\n",
    "probs = [x / sum(probs) for x in probs]\n",
    "\n",
    "def augment(x):\n",
    "    aug = np.random.choice(choices, p=probs)\n",
    "    if random.random() < 0.5:\n",
    "        x = reflect(x)\n",
    "    return scale_data(aug(x))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "def fetch_data(batch_size=BATCH_SIZE):\n",
    "    global x_train, y_train\n",
    "    while True:\n",
    "        idx = np.random.permutation(x_train.shape[0])\n",
    "        x_train, y_train = x_train[idx], y_train[idx]\n",
    "        for i in range(0, x_train.shape[0], BATCH_SIZE):\n",
    "            yield augment(x_train[i:i+BATCH_SIZE]), y_train[i:i+BATCH_SIZE]\n",
    "        \n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    fetch_data,\n",
    "    output_shapes=((None, x_train.shape[1]), (None,)),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    ").prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 20m 55s]\n",
      "val_loss: 0.8975167274475098\n",
      "\n",
      "Best val_loss So Far: 0.8975167274475098\n",
      "Total elapsed time: 00h 20m 55s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4                 |1                 |gru_layers\n",
      "64                |64                |gru_units\n",
      "0.0001            |1e-06             |l2_reg\n",
      "0.2               |0.2               |dropout\n",
      "\n",
      "Epoch 1/600\n",
      "   4/3978 [..............................] - ETA: 1:10 - loss: 2.0551 - accuracy: 0.3594    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0165s vs `on_train_batch_end` time: 0.0593s). Check your callbacks.\n",
      "3978/3978 [==============================] - 84s 18ms/step - loss: 1.0721 - accuracy: 0.4951 - val_loss: 1.0445 - val_accuracy: 0.5051 - lr: 0.0100\n",
      "Epoch 2/600\n",
      "3978/3978 [==============================] - 70s 18ms/step - loss: 1.0585 - accuracy: 0.4982 - val_loss: 1.0411 - val_accuracy: 0.5051 - lr: 0.0100\n",
      "Epoch 3/600\n",
      "2513/3978 [=================>............] - ETA: 25s - loss: 1.0478 - accuracy: 0.4989"
     ]
    }
   ],
   "source": [
    "# Use keras tuner to run through all possible models\n",
    "# After this phase, simply look through tensorboard to select the best one\n",
    "import datetime\n",
    "\n",
    "def build_model(hp):\n",
    "    input_layer = Input(shape=(x_train.shape[1],))\n",
    "    x = input_layer\n",
    "    x = Reshape(\n",
    "        target_shape=(num_consec, x_train.shape[1] // (num_consec))\n",
    "    )(x)\n",
    "    # for layer in range(hp.Choice('dense_layers', [0, 1])):\n",
    "    #     x = Dense(hp.Choice('dense_units', [32, 64, 128]), activation='relu')(x)\n",
    "    \n",
    "    for layer in range(hp.Choice('gru_layers', [1, 2, 4])):\n",
    "        x = Bidirectional(GRU(\n",
    "            hp.Choice('gru_units', [16, 64, 128]),\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2_reg', [0., 1e-6, 1e-4])),\n",
    "            dropout=hp.Choice('dropout', [0., 0.2])\n",
    "        ))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dense(\n",
    "        3\n",
    "    )(x)\n",
    "\n",
    "    output_layer = Softmax()(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "                          \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(clipnorm=2.0, lr=1e-2),#tf.keras.optimizers.SGD(lr=1e-2, momentum=0.99, nesterov=True, clipnorm=2.0),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "output_dir = './tensorboard/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    output_dir, \n",
    "    histogram_freq=1,\n",
    ")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=15),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=12),\n",
    "    tensorboard_callback\n",
    "]\n",
    "          \n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "#     distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    directory=\"tensorboard\",\n",
    "    project_name=\"gru-model\",\n",
    "    overwrite=True\n",
    ")\n",
    " \n",
    "tuner.search(\n",
    "    # x_train, \n",
    "    # y_train, \n",
    "    # epochs=1000, \n",
    "    # batch_size=1024,\n",
    "    # shuffle=True,\n",
    "    dataset,\n",
    "    steps_per_epoch=10 * x_train.shape[0] // BATCH_SIZE,\n",
    "    epochs=600,\n",
    "    validation_data=(x_val, y_val),\n",
    "    # class_weight={i: class_weights[i] for i in range(3)},\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.130116581916809\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "# Implement temperature scaling for calibration\n",
    "def temp_scaling(y_logits, y_val, max_iter=150):\n",
    "    temp = tf.Variable(initial_value=1.0, trainable=True, dtype=tf.float32)\n",
    "    def compute_loss():\n",
    "        y_pred_model_w_temp = tf.math.divide(y_logits, temp)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\\\n",
    "          tf.convert_to_tensor(tf.keras.utils.to_categorical(y_val)), \\\n",
    "                               y_pred_model_w_temp))\n",
    "        return loss\n",
    "    optimizer = tf.optimizers.Adam()\n",
    "    print('Temperature Initial value: {}'.format(temp.numpy()))\n",
    "    for i in range(max_iter):\n",
    "        opts = optimizer.minimize(compute_loss, var_list=[temp])\n",
    "    print('Temperature Final value: {}'.format(temp.numpy()))\n",
    "    return temp.numpy()\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "compute_logits = K.function([model.layers[0].input], [model.layers[-2].output])\n",
    "\n",
    "y_logits = compute_logits(x_val)[0]\n",
    "temp = temp_scaling(y_logits, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      2222\n",
      "           1       0.95      0.94      0.95      1103\n",
      "           2       0.92      0.92      0.92      1095\n",
      "\n",
      "    accuracy                           0.94      4420\n",
      "   macro avg       0.94      0.93      0.93      4420\n",
      "weighted avg       0.94      0.94      0.94      4420\n",
      "\n",
      "[[0.94149415 0.02205221 0.03645365]\n",
      " [0.05711695 0.93834995 0.00453309]\n",
      " [0.08127854 0.         0.91872146]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(model.predict(x_val), axis=1)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.saving import hdf5_format\n",
    "import h5py\n",
    "\n",
    "# temp = 1.0\n",
    "with h5py.File(f'./hitnet_conv_model_predict_direction-{num_consec}-{left_window}-{right_window}.h5', mode='w') as f:\n",
    "    hdf5_format.save_model_to_hdf5(model, f)\n",
    "    f.attrs['temperature'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from ai_badminton.trajectory import Trajectory\n",
    "from ai_badminton.hit_detector import AdhocHitDetector, MLHitDetector\n",
    "from ai_badminton.pose import Pose, read_player_poses, process_pose_file\n",
    "from ai_badminton.court import Court, read_court\n",
    "from ai_badminton.video_annotator import annotate_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from scipy.stats import mode\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "def read_court(filename):\n",
    "    file = open(filename, 'r')\n",
    "    coordinates = [[float(x) for x in line.split(';')] for line in file]\n",
    "    return coordinates\n",
    "\n",
    "def visualize(x, y):\n",
    "    print(x.shape, y.shape)\n",
    "    cdict = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "    plt.figure()\n",
    "    for g in np.unique(y):\n",
    "        ix = np.where(y == g)\n",
    "        plt.scatter(*x[ix, -4:, :].T, c=cdict[g], label=g)\n",
    "        plt.scatter(*x[ix, 0, :].T, c=cdict[g], label=g)\n",
    "    plt.show()\n",
    "    \n",
    "def resample(series, s):\n",
    "    flatten = False\n",
    "    if len(series.shape) == 1:\n",
    "        series.resize((series.shape[0], 1))\n",
    "        series = series.astype('float64')\n",
    "        flatten = True\n",
    "    series = resize(\n",
    "        series, (int(s * series.shape[0]), series.shape[1]),\n",
    "    )\n",
    "    if flatten:\n",
    "        series = series.flatten()\n",
    "    return series   \n",
    "\n",
    "eps = 1e-6\n",
    "def reflect(x):\n",
    "    x = np.array(x)\n",
    "    idx = np.abs(x) < eps\n",
    "    for i in range(0, x.shape[1], 2):\n",
    "        x[:, i] = -x[:, i]\n",
    "    x[idx] = 0.\n",
    "    return x\n",
    "\n",
    "# Identify first hit by distance to pose\n",
    "# and then alternate hits\n",
    "def dist_to_pose(pose, p):\n",
    "    pose = pose.reshape(17, 2)\n",
    "    p = p.reshape(1, 2)\n",
    "    D = np.sum((pose - p) * (pose - p), axis=1)\n",
    "    return min(D)\n",
    "\n",
    "def scale_data(x):\n",
    "    x = np.array(x)\n",
    "    def scale_by_col(x, cols):\n",
    "        x_ = np.array(x[:, cols])\n",
    "        idx = np.abs(x_) < eps\n",
    "        m, M = np.min(x_[~idx]), np.max(x_[~idx])\n",
    "        x_[~idx] = (x_[~idx] - m) / (M - m) + 1\n",
    "        x[:, cols] = x_\n",
    "        return x\n",
    "\n",
    "    even_cols = [2*i for i in range(x.shape[1] // 2)]\n",
    "    odd_cols = [2*i+1 for i in range(x.shape[1] // 2)]\n",
    "    x = scale_by_col(x, even_cols)\n",
    "    x = scale_by_col(x, odd_cols)\n",
    "    return x\n",
    "\n",
    "identity = lambda x: x\n",
    "def drop_consecutive(x, rep_value=0.):\n",
    "    x = np.array(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        j = random.randint(0, num_consec-1)\n",
    "        x[i][max(0, 78*(j-2)):min(78*(j+2), 78*num_consec)] = rep_value\n",
    "    return x\n",
    "\n",
    "def corrupt_consecutive(x, rep_value=0.):\n",
    "    x = np.array(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        j = random.randint(0, num_consec-1)\n",
    "        l, r = max(0, 78*(j-2)), min(78*(j+2), 78*num_consec)\n",
    "        x[i][l:r] = np.random.rand(1, r-l)\n",
    "    return x\n",
    "\n",
    "def drop_data(x, rep_value=0, keep_prob=0.95):\n",
    "    x = np.array(x)\n",
    "    # Corrupt 15% of the data\n",
    "    indices = np.random.choice(\n",
    "        np.arange(x.size), replace=False,\n",
    "        size=int(x.size * (1 - keep_prob))\n",
    "    )\n",
    "    x[np.unravel_index(indices, x.shape)] = rep_value\n",
    "    return x\n",
    "\n",
    "def corrupt_data(x, keep_prob=0.95):\n",
    "    x = np.array(x)\n",
    "    idx = np.abs(x) < eps\n",
    "    # Corrupt 15% of the data\n",
    "    indices = np.random.choice(\n",
    "        np.arange(x.size), replace=False,\n",
    "        size=int(x.size * (1 - keep_prob))\n",
    "    )\n",
    "    shape = x[np.unravel_index(indices, x.shape)].shape\n",
    "    low, hi = max(np.min(x[:,0::2]), np.min(x[:,1::2])), min(np.max(x[:,0::2]), np.max(x[:,1::2]))\n",
    "    target = np.random.rand(*shape) * (hi-low) + low\n",
    "    x[np.unravel_index(indices, x.shape)] = target\n",
    "    x[idx] = 0.\n",
    "    return x\n",
    "\n",
    "def jiggle_and_rotate(x):\n",
    "    # Randomly shift by a vector in [0, 30]\n",
    "    # and rotate by a random amount between -10 and 10 degrees\n",
    "    x = np.array(x.reshape((x.shape[0], x.shape[1] // 2, 2)))\n",
    "    idx = np.abs(x) < eps\n",
    "    # shift does nothing when we rescale after\n",
    "    # shift = np.random.rand(1, 2) * 30\n",
    "    angle = (np.random.rand() - 0.5) * math.pi / 180 * 30\n",
    "    rotate = np.array([[math.cos(angle), -math.sin(angle)], \n",
    "                       [math.sin(angle), math.cos(angle)]])\n",
    "    a, b = np.random.rand() * 0.1, np.random.rand() * 0.1\n",
    "    shear = np.array([[1+a*b, a], \n",
    "                      [b,     1]])\n",
    "    x = x @ shear @ rotate\n",
    "    x[idx] = 0.\n",
    "    x = x.reshape((x.shape[0], x.shape[1] * 2))\n",
    "    return x\n",
    "\n",
    "drop_random_and_jiggle = lambda x: drop_data(jiggle_and_rotate(x), 0, 0.95)\n",
    "corrupt_random_and_jiggle = lambda x: corrupt_data(jiggle_and_rotate(x), 0.95)\n",
    "drop_consecutive_and_jiggle = lambda x: drop_consecutive(jiggle_and_rotate(x))\n",
    "corrupt_consecutive_and_jiggle = lambda x: corrupt_consecutive(jiggle_and_rotate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match1 1_02_03 is hard [1, 0] [5266.931744878903, 1e+99]\n",
      "Manual label applied.\n",
      "match1 1_02_04 1 [2, 0]\n",
      "Manual label applied.\n",
      "match1 1_01_00 2 [3, 7]\n",
      "match1 1_06_06 is hard [2, 3] [682559.7210577, 974.929612210002]\n",
      "match1 1_02_02 1 [4, 2]\n",
      "Manual label applied.\n",
      "match1 1_06_08 1 [4, 0]\n",
      "Manual label applied.\n",
      "match1 1_03_06 2 [3, 5]\n",
      "match1 1_06_09 1 [11, 3]\n",
      "match1 1_02_01 2 [0, 6]\n",
      "Manual label applied.\n",
      "match1 1_02_00 1 [11, 7]\n",
      "match1 1_03_04 2 [0, 3]\n",
      "Manual label applied.\n",
      "match1 1_03_05 2 [3, 10]\n",
      "match2 1_02_03 2 [1, 4]\n",
      "match2 1_08_12 1 [6, 0]\n",
      "match2 1_08_11 is hard [4, 3] [1116.9742584088992, 1204.2098843728977]\n",
      "match2 1_04_03 2 [2, 4]\n",
      "match2 1_06_08 is hard [4, 3] [2477.160291976099, 68.54406989089972]\n",
      "match2 1_09_12 1 [8, 3]\n",
      "match2 1_00_02 1 [12, 6]\n",
      "match2 1_06_09 2 [1, 9]\n",
      "match3 1_01_00 2 [0, 13]\n",
      "match3 2_10_12 1 [5, 1]\n",
      "match3 1_12_17 is hard [4, 4] [5.7387200101000175, 354.46816523080025]\n",
      "match3 1_08_10 is hard [1, 2] [4412.541963218499, 1204.3166403475989]\n",
      "Manual label applied.\n",
      "match3 2_18_15 2 [1, 36]\n",
      "match3 2_04_07 2 [6, 15]\n",
      "match3 3_11_10 2 [1, 5]\n",
      "match4 3_18_17 1 [14, 10]\n",
      "match4 2_05_07 2 [6, 8]\n",
      "match4 2_14_17 is hard [4, 4] [1767.4863214409038, 330555.28941241157]\n",
      "match4 1_15_10 1 [10, 6]\n",
      "match4 1_03_02 1 [11, 5]\n",
      "match4 3_07_05 is hard [2, 3] [1027.9010970708982, 376614.00944341]\n",
      "match4 2_02_05 2 [6, 12]\n",
      "match4 3_02_00 2 [3, 10]\n",
      "match5 2_15_13 1 [20, 2]\n",
      "match5 1_01_02 1 [16, 3]\n",
      "match5 2_20_17 1 [26, 2]\n",
      "match5 1_21_19 2 [1, 28]\n",
      "match5 1_01_01 2 [2, 26]\n",
      "match5 1_19_18 2 [0, 9]\n",
      "match6 1_19_12 2 [1, 9]\n",
      "match6 1_15_06 2 [2, 24]\n",
      "match6 1_11_04 1 [13, 7]\n",
      "match6 1_05_03 2 [6, 32]\n",
      "match6 1_02_00 1 [9, 5]\n",
      "match7 2_05_03 2 [6, 24]\n",
      "match7 2_14_15 1 [11, 7]\n",
      "match7 3_08_05 2 [0, 17]\n",
      "match7 1_02_01 1 [20, 3]\n",
      "match7 1_12_13 1 [15, 5]\n",
      "match8 3_15_08 1 [4, 0]\n",
      "match8 2_03_06 2 [3, 31]\n",
      "match8 1_01_00 1 [10, 1]\n",
      "match8 2_10_12 1 [15, 2]\n",
      "match8 3_17_12 2 [4, 13]\n",
      "match8 3_21_13 1 [11, 1]\n",
      "match8 1_05_13 2 [2, 7]\n",
      "match8 3_02_00 is hard [1, 1] [580117.6390523058, 128.41058857959956]\n",
      "Manual label applied.\n",
      "match9 1_02_03 2 [0, 13]\n",
      "match9 1_01_03 2 [6, 30]\n",
      "match9 1_07_10 1 [17, 4]\n",
      "match9 1_05_06 1 [11, 0]\n",
      "match9 1_07_11 2 [1, 9]\n",
      "match9 1_07_14 1 [5, 3]\n",
      "match9 1_06_06 1 [7, 1]\n",
      "match9 1_07_07 1 [8, 3]\n",
      "match9 1_04_05 1 [9, 1]\n",
      "match10 2_04_02 1 [7, 4]\n",
      "match10 1_03_01 is hard [9, 8] [990.7883616545008, 3734.0805698024]\n",
      "match10 2_14_08 2 [3, 20]\n",
      "match10 1_03_03 2 [6, 12]\n",
      "match10 1_12_16 1 [10, 4]\n",
      "match11 1_07_06 1 [11, 1]\n",
      "match11 2_15_04 1 [18, 6]\n",
      "match11 2_05_00 1 [10, 3]\n",
      "match11 1_03_01 2 [2, 11]\n",
      "match11 1_13_13 1 [23, 7]\n",
      "match12 3_03_03 2 [2, 11]\n",
      "match12 2_01_01 2 [0, 14]\n",
      "match12 1_01_00 1 [20, 1]\n",
      "match12 2_05_14 1 [23, 2]\n",
      "match12 1_10_12 2 [11, 14]\n",
      "match13 2_07_05 1 [5, 0]\n",
      "match13 2_17_11 2 [2, 13]\n",
      "match13 1_17_15 2 [4, 7]\n",
      "match13 1_09_10 1 [14, 6]\n",
      "match13 2_06_05 1 [24, 6]\n",
      "match13 2_09_08 2 [1, 3]\n",
      "match14 2_21_17 2 [3, 11]\n",
      "match14 2_13_06 2 [4, 13]\n",
      "match14 1_17_14 2 [5, 20]\n",
      "match14 2_15_10 1 [4, 1]\n",
      "match14 2_19_13 1 [19, 3]\n",
      "match15 1_21_12 is hard [4, 4] [1636.9464822099958, 285105.35345104]\n",
      "match15 2_14_08 1 [6, 0]\n",
      "match15 2_18_14 2 [8, 27]\n",
      "match15 2_16_12 2 [6, 15]\n",
      "match15 2_19_14 2 [3, 22]\n",
      "match16 3_12_06 1 [12, 8]\n",
      "match16 2_08_08 1 [14, 3]\n",
      "match16 3_14_09 1 [10, 1]\n",
      "match16 3_17_16 1 [8, 5]\n",
      "match16 1_03_06 2 [3, 16]\n",
      "match16 1_13_20 1 [12, 0]\n",
      "match17 1_15_13 1 [12, 2]\n",
      "match17 2_01_01 1 [9, 6]\n",
      "match17 2_08_05 2 [2, 14]\n",
      "match17 1_02_02 2 [2, 8]\n",
      "match17 2_15_11 1 [12, 1]\n",
      "match17 2_18_11 2 [5, 8]\n",
      "match18 2_02_02 1 [15, 1]\n",
      "match18 3_03_05 2 [1, 27]\n",
      "match18 3_16_17 1 [12, 1]\n",
      "match18 3_20_19 1 [12, 4]\n",
      "match18 3_12_14 2 [2, 12]\n",
      "match18 1_06_12 1 [10, 3]\n",
      "match19 1_01_03 1 [21, 6]\n",
      "match19 2_14_08 2 [2, 8]\n",
      "match19 1_07_08 2 [1, 11]\n",
      "match19 1_01_01 2 [2, 11]\n",
      "match19 2_12_06 1 [12, 2]\n",
      "match20 2_07_08 1 [9, 3]\n",
      "match20 2_00_01 1 [9, 0]\n",
      "match20 1_11_10 2 [6, 9]\n",
      "match20 1_09_05 2 [5, 15]\n",
      "match20 2_05_08 1 [22, 3]\n",
      "match20 2_19_14 2 [3, 13]\n",
      "match21 1_16_17 1 [21, 2]\n",
      "match21 2_12_08 2 [2, 11]\n",
      "match21 1_19_19 1 [7, 2]\n",
      "match21 2_04_04 1 [10, 4]\n",
      "match21 1_02_01 2 [2, 14]\n",
      "match21 2_02_03 2 [1, 16]\n",
      "match21 2_09_08 1 [19, 5]\n",
      "match22 2_17_18 1 [16, 7]\n",
      "match22 2_18_18 2 [2, 17]\n",
      "match22 1_07_02 1 [10, 3]\n",
      "match22 3_15_13 1 [10, 4]\n",
      "match22 1_02_01 1 [26, 6]\n"
     ]
    }
   ],
   "source": [
    "num_consec = 12 # Jui: read the paper for the correct parameters\n",
    "left_window = 6\n",
    "right_window = 0\n",
    "matches = list('match' + str(i) for i in range(1, 23))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, minmax_scale\n",
    "\n",
    "manual_label = {\n",
    "    ('match1', '1_02_04'): 2,\n",
    "    ('match1', '1_06_08'): 1,\n",
    "    ('match1', '1_02_02'): 1,\n",
    "    ('match1', '1_02_01'): 2,\n",
    "    ('match1', '1_03_04'): 2,\n",
    "    ('match1', '1_02_03'): 1,\n",
    "    ('match3', '1_08_10'): 2,\n",
    "    ('match8', '3_02_00'): 2,\n",
    "}\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for match in matches:\n",
    "    basedir = f'{data_dir}/%s' % match\n",
    "    for video in os.listdir('%s/rally_video/' % basedir):\n",
    "        if '.mp4' not in video:\n",
    "            continue\n",
    "        for speed in [1.0]:#[0.833, 0.9, 1.0, 1.1, 1.2]:\n",
    "            rally, _ = os.path.splitext(video)\n",
    "            trajectory = Trajectory(\n",
    "                '%s/ball_trajectory/%s_ball_predicted.csv' % (basedir, rally),\n",
    "                interp=False\n",
    "            )\n",
    "            hit = pd.read_csv('%s/shot/%s_hit.csv' % (basedir, rally))\n",
    "\n",
    "            poses = read_player_poses('%s/poses/%s' % (basedir, rally))\n",
    "            bottom_player, top_player = poses[0], poses[1]\n",
    "\n",
    "            x_list, y_list = [], []\n",
    "            court_pts = read_court('%s/court/%s.out' % (basedir, rally))\n",
    "            corners = np.array([court_pts[1], court_pts[2], court_pts[0], court_pts[3]]).flatten()\n",
    "            \n",
    "            cap = cv2.VideoCapture('%s/rally_video/%s' % (basedir, video))\n",
    "            _, frame = cap.read()\n",
    "            height, width = frame.shape[:2]         \n",
    "            \n",
    "            hit = hit.values[:, 1]\n",
    "            if speed < 1:\n",
    "                # NTS: speed < 1 actually means sequence gets faster\n",
    "                hit = hit + shift(hit, -1) + shift(hit, +1)\n",
    "                        \n",
    "            trajectory.X = resample(np.array(trajectory.X), speed)\n",
    "            trajectory.Y = resample(np.array(trajectory.Y), speed)\n",
    "            hit = resample(hit, speed).round()\n",
    "            bottom_player = resample(bottom_player.values, speed)\n",
    "            top_player = resample(top_player.values, speed)\n",
    "            \n",
    "            y_new = np.array(hit)\n",
    "            if speed != 1:\n",
    "                for i in range(y_new.shape[0] - 1):\n",
    "                    if i+3 < y_new.shape[0] and y_new[i] and y_new[i+1] and y_new[i+2] and y_new[i+3]:\n",
    "                        y_new[i] = y_new[i+1] = y_new[i+3] = 0.\n",
    "                    if i+2 < y_new.shape[0] and y_new[i] and y_new[i+1] and y_new[i+2]:\n",
    "                        y_new[i] = y_new[i+2] = 0.\n",
    "                    if y_new[i] and y_new[i+1]:\n",
    "                        y_new[i] = 0.\n",
    "                        \n",
    "            # Majority vote for who started the rally\n",
    "            # If hit number is odd, then whoever started the rally\n",
    "            # is the opposite of whoever was detected.\n",
    "            votes = [0, 0]\n",
    "            best_dist = [1e99, 1e99]\n",
    "            nhit = 0\n",
    "            for i in range(y_new.shape[0]):\n",
    "                if not y_new[i]:\n",
    "                    continue\n",
    "\n",
    "                p = np.array([trajectory.X[i], trajectory.Y[i]])\n",
    "                db = dist_to_pose(bottom_player[i], p)\n",
    "                dt = dist_to_pose(top_player[i], p)\n",
    "                person = 0\n",
    "                if db < dt:\n",
    "                    person = 1\n",
    "                else:\n",
    "                    person = 2\n",
    "\n",
    "                if nhit % 2:\n",
    "                    person = 3 - person\n",
    "\n",
    "                votes[person - 1] += 1\n",
    "                best_dist[person - 1] = min(best_dist[person - 1], min(db, dt))\n",
    "\n",
    "                nhit += 1\n",
    "\n",
    "            if abs(votes[0] - votes[1]) < 2:\n",
    "                print(match, rally, 'is hard', votes, best_dist)\n",
    "            else:\n",
    "                print(match, rally, 1 if votes[0] > votes[1] else 2, votes)\n",
    "\n",
    "            last = 2 if votes[0] > votes[1] else 1\n",
    "            if (match, rally) in manual_label:\n",
    "                last = 3 - manual_label[match, rally]\n",
    "                print('Manual label applied.')\n",
    "            for i in range(y_new.shape[0]):\n",
    "                if not y_new[i]:\n",
    "                    continue\n",
    "\n",
    "                y_new[i] = 3 - last\n",
    "                last = y_new[i]\n",
    "                \n",
    "            for i in range(num_consec):\n",
    "                end = min(len(trajectory.X), len(hit))-num_consec+i+1\n",
    "                x_bird = np.array(list(zip(trajectory.X[i:end], trajectory.Y[i:end])))\n",
    "\n",
    "                # Use entire pose\n",
    "                x_pose = np.hstack([bottom_player[i:end], top_player[i:end]])\n",
    "                x = np.hstack([x_bird, x_pose, np.array([corners for j in range(i, end)])])\n",
    "                y = y_new[i:end]\n",
    "                x_list.append(x)\n",
    "                y_list.append(y)\n",
    "\n",
    "            x_t = np.hstack(x_list)\n",
    "            if right_window > 0:\n",
    "                y_t = np.max(np.column_stack(y_list[left_window:-right_window]), axis=1)\n",
    "            else:\n",
    "                y_t = np.max(np.column_stack(y_list[left_window:]), axis=1)\n",
    "                    \n",
    "            # y_t = np.column_stack(y_list).astype('float')\n",
    "            # y_t = mode(np.column_stack(y_list[left_window:-right_window]), axis=1).mode.flatten()\n",
    "            # for i in range(y_t.shape[0]):\n",
    "            #     val, cnt = np.unique(y_t[i], return_counts=True)\n",
    "            #     val = val.astype('int')\n",
    "            #     cnt = cnt.astype('float')\n",
    "            #     y_t[i, 0:3] = 0\n",
    "            #     y_t[i, val] = cnt / subwindow_size\n",
    "            # y_t = y_t[:, :3]\n",
    "\n",
    "            augmentations = [identity]# + [jiggle_and_rotate]*2# + [drop_consecutive_and_jiggle] + [corrupt_consecutive_and_jiggle]\n",
    "            #+ [corrupt_and_jiggle] + [drop_and_jiggle]# + [jiggle_and_rotate] + [drop_and_jiggle] + [corrupt_and_jiggle]\n",
    "            for transform in augmentations:\n",
    "                x_train.append(scale_data(transform(x_t)))\n",
    "                y_train.append(y_t)\n",
    "                \n",
    "                # x_train.append(scale_data(transform(reflect(x_t))))\n",
    "                # y_train.append(y_t)\n",
    "\n",
    "x_train = np.vstack(x_train)\n",
    "y_train = np.hstack(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_09_07.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_09_07.mp4 1 [20, 3]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_07_06.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_07_06.mp4 is hard [5, 6] [1689.2631038501008, 1808.8286952228966]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_06_03.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_06_03.mp4 2 [4, 8]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_05_02.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_05_02.mp4 1 [13, 3]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/2_03_10.mp4\n",
      "/home/work_space/data/test_match1/rally_video/2_03_10.mp4 1 [18, 1]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_07_03.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_07_03.mp4 1 [19, 4]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/2_03_08.mp4\n",
      "/home/work_space/data/test_match1/rally_video/2_03_08.mp4 is hard [2, 1] [268547.24660605, 319816.2775039634]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/2_02_07.mp4\n",
      "/home/work_space/data/test_match1/rally_video/2_02_07.mp4 1 [6, 0]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_05_03.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_05_03.mp4 1 [11, 1]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_07_04.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_07_04.mp4 is hard [2, 1] [369156.92521387694, 371513.396241242]\n",
      "Fetching video: /home/work_space/data/test_match1/rally_video/1_09_06.mp4\n",
      "/home/work_space/data/test_match1/rally_video/1_09_06.mp4 is hard [1, 1] [291310.29732485, 321908.5355976704]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_04_04.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_04_04.mp4 is hard [4, 3] [1124.9216913124026, 92896.5303993429]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_19_15.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_19_15.mp4 2 [5, 18]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_03_03.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_03_03.mp4 2 [5, 7]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/2_08_12.mp4\n",
      "/home/work_space/data/test_match2/rally_video/2_08_12.mp4 1 [18, 3]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_11_11.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_11_11.mp4 2 [5, 18]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/1_13_12.mp4\n",
      "/home/work_space/data/test_match2/rally_video/1_13_12.mp4 2 [4, 15]\n",
      "Fetching video: /home/work_space/data/test_match2/rally_video/2_02_05.mp4\n",
      "/home/work_space/data/test_match2/rally_video/2_02_05.mp4 2 [7, 19]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_10_16.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_10_16.mp4 2 [2, 9]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_08_08.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_08_08.mp4 2 [1, 8]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_05_02.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_05_02.mp4 2 [1, 25]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_06_06.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_06_06.mp4 2 [2, 6]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_03_02.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_03_02.mp4 1 [9, 3]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_09_12.mp4\n",
      "Failed data fetch for video: /home/work_space/data/test_match3/rally_video/1_09_12.mp4\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_06_05.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_06_05.mp4 2 [2, 5]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_05_03.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_05_03.mp4 2 [0, 3]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_02_00.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_02_00.mp4 2 [2, 20]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_08_09.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_08_09.mp4 2 [0, 6]\n",
      "Fetching video: /home/work_space/data/test_match3/rally_video/1_09_15.mp4\n",
      "/home/work_space/data/test_match3/rally_video/1_09_15.mp4 1 [5, 1]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# Get validation data\n",
    "x_val, y_val = [], []\n",
    "base_dir = Path(data_dir)\n",
    "for match_dir in base_dir.iterdir():\n",
    "    if 'test_match' not in str(match_dir):\n",
    "        continue\n",
    "    rally_video_path = match_dir / \"rally_video\"\n",
    "\n",
    "    for video_path in rally_video_path.iterdir():\n",
    "        try:\n",
    "            print(f\"Fetching video: {str(video_path)}\")\n",
    "            stem = video_path.stem\n",
    "            trajectory_path = match_dir / \"ball_trajectory\" / (stem + \"_ball_predicted.csv\")\n",
    "            hit_path = match_dir / \"shot\" / (stem + \"_hit.csv\")\n",
    "            court_path = match_dir / \"court\" / (stem + \".out\")\n",
    "            poses_path_prefix = match_dir / \"poses\" / stem\n",
    "\n",
    "            poses_bottom_path = Path(str(poses_path_prefix) + \"_player_bottom.csv\") \n",
    "            poses_top_path = Path(str(poses_path_prefix) + \"_player_top.csv\") \n",
    "\n",
    "            assert trajectory_path.is_file(), f\"Trajectory file does not exist for: {video_path}\"\n",
    "            assert hit_path.is_file(), f\"Hit file does not exist for: {video_path}\"\n",
    "            assert court_path.is_file(), f\"Court file does not exist for: {video_path}\"\n",
    "            assert poses_bottom_path.is_file(), f\"Bottom pose file does not exist for: {video_path}\"\n",
    "            assert poses_top_path.is_file(), f\"Top pose file does not exist for: {video_path}\"\n",
    "\n",
    "            trajectory = Trajectory(str(trajectory_path), interp=False)\n",
    "            hit = pd.read_csv(str(hit_path))\n",
    "            poses = read_player_poses(str(poses_path_prefix))\n",
    "            bottom_player, top_player = poses[0], poses[1]\n",
    "            court_pts = read_court(str(court_path))\n",
    "            corners = np.array([court_pts[1], court_pts[2], court_pts[0], court_pts[3]]).flatten()\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            _, frame = cap.read()\n",
    "            height, width = frame.shape[:2]\n",
    "        except:\n",
    "            print('Failed data fetch for video:', str(video_path))\n",
    "            continue\n",
    "        \n",
    "        # Identify first hit by distance to pose\n",
    "        # and then alternate hits\n",
    "        def dist_to_pose(pose, p):\n",
    "            pose = pose.reshape(17, 2)\n",
    "            p = p.reshape(1, 2)\n",
    "            D = np.sum((pose - p) * (pose - p), axis=1)\n",
    "            return min(D)\n",
    "\n",
    "        y_new = np.array(hit.hit.to_numpy())\n",
    "        # Majority vote for who started the rally\n",
    "        # If hit number is odd, then whoever started the rally\n",
    "        # is the opposite of whoever was detected.\n",
    "        votes = [0, 0]\n",
    "        best_dist = [1e99, 1e99]\n",
    "        nhit = 0\n",
    "        for i in range(y_new.shape[0]):\n",
    "            if not y_new[i]:\n",
    "                continue\n",
    "\n",
    "            p = np.array([trajectory.X[i], trajectory.Y[i]])\n",
    "            db = dist_to_pose(bottom_player.values[i], p)\n",
    "            dt = dist_to_pose(top_player.values[i], p)\n",
    "            person = 0\n",
    "            if db < dt:\n",
    "                person = 1\n",
    "            else:\n",
    "                person = 2\n",
    "\n",
    "            if nhit % 2:\n",
    "                person = 3 - person\n",
    "\n",
    "            votes[person - 1] += 1\n",
    "            best_dist[person - 1] = min(best_dist[person - 1], min(db, dt))\n",
    "\n",
    "            nhit += 1\n",
    "\n",
    "        if abs(votes[0] - votes[1]) < 2:\n",
    "            print(rally_video_path / video_path, 'is hard', votes, best_dist)\n",
    "        else:\n",
    "            print(rally_video_path / video_path, 1 if votes[0] > votes[1] else 2, votes)\n",
    "\n",
    "        last = 2 if votes[0] > votes[1] else 1\n",
    "        if votes[0] == votes[1]:\n",
    "            last = 1 if best_dist[0] < best_dist[1] else 2\n",
    "\n",
    "        for i in range(y_new.shape[0]):\n",
    "            if not y_new[i]:\n",
    "                continue\n",
    "\n",
    "            y_new[i] = 3 - last\n",
    "            last = y_new[i]\n",
    "\n",
    "        # last = 0\n",
    "        # last_id = -1\n",
    "        # for i in range(y_new.shape[0]):\n",
    "        #     if y_new[i] > 0:\n",
    "        #         if last_id >= 0:\n",
    "        #             for j in range(last_id, i):\n",
    "        #                 y_new[j] = last\n",
    "        #         last = y_new[i]\n",
    "        #         last_id = i\n",
    "        #     y_new[i] = last\n",
    "\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for i in range(num_consec):\n",
    "            end = min(len(trajectory.X), len(hit.hit))-num_consec+i+1\n",
    "            x_bird = np.array(list(zip(trajectory.X[i:end], trajectory.Y[i:end])))\n",
    "\n",
    "            # Use entire pose\n",
    "            x_pose = np.hstack([bottom_player.values[i:end], top_player.values[i:end]])\n",
    "            x = np.hstack([x_bird, x_pose, np.array([corners for j in range(i, end)])])\n",
    "\n",
    "            y = y_new[i:end]\n",
    "            x_list.append(x)\n",
    "            y_list.append(y)\n",
    "            \n",
    "        x_t = np.hstack(x_list)\n",
    "        if right_window > 0:\n",
    "            y_t = np.max(np.column_stack(y_list[left_window:-right_window]), axis=1)\n",
    "        else:\n",
    "            y_t = np.max(np.column_stack(y_list[left_window:]), axis=1)\n",
    "\n",
    "            \n",
    "        # y_t = np.column_stack(y_list).astype('float')\n",
    "        # y_t = mode(np.column_stack(y_list[left_window:-right_window]), axis=1).mode.flatten()\n",
    "        # for i in range(y_t.shape[0]):\n",
    "        #     val, cnt = np.unique(y_t[i], return_counts=True)\n",
    "        #     val = val.astype('int')\n",
    "        #     cnt = cnt.astype('float')\n",
    "        #     y_t[i, 0:3] = 0\n",
    "        #     y_t[i, val] = cnt / subwindow_size\n",
    "        # y_t = y_t[:, :3]\n",
    "\n",
    "        x_val.append(scale_data(x_t))\n",
    "        y_val.append(y_t)\n",
    "\n",
    "x_val = np.vstack(x_val)\n",
    "y_val = np.hstack(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
